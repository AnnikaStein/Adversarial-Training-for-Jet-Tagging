{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'um106329'\n",
    "dataset_path = '/hpcwork/' + user + '/jet_flavor_MLPhysics/dataset/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some initial investigations\n",
    "Here, the problem is that the usual way of reading a JSON does not work, because the JSON is sort of a \"list of JSONs\" in different lines of the zipped file. So one gets rather strange error messages when unzipping / extracting the data.\n",
    "\n",
    "Here are the links where I got the ideas from:  \n",
    "<a href=\"https://stackoverflow.com/questions/56677516/how-to-open-a-json-gz-file-and-return-to-dictionary-in-python\" target=\"_blank\">https://stackoverflow.com/questions/56677516/how-to-open-a-json-gz-file-and-return-to-dictionary-in-python</a>  \n",
    "<a href=\"https://stackoverflow.com/questions/65276808/how-to-read-json-string-from-gzip\" target=\"_blank\">https://stackoverflow.com/questions/65276808/how-to-read-json-string-from-gzip</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## awkward to the rescue?\n",
    "<a href=\"https://github.com/scikit-hep/awkward-1.0/issues/437\" target=\"_blank\">https://github.com/scikit-hep/awkward-1.0/issues/437</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward1 as ak\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
      "Wall time: 5.48 µs\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-829cc0a660ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbuilder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mak\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArrayBuilder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mlineno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"dataset.json.gz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlineno\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m114919\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%H:%M:%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\":\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlineno\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m114919\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"percent complete\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/my-env/lib/python3.8/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte"
     ]
    }
   ],
   "source": [
    "%time\n",
    "builder = ak.ArrayBuilder()\n",
    "for lineno, line in enumerate(open(dataset_path+\"dataset.json.gz\")):\n",
    "    if lineno % 114919 == 0:\n",
    "        print(time.strftime(\"%H:%M:%S\"), \":\", lineno/114919, \"percent complete\")\n",
    "    builder.append(json.loads(line))\n",
    "array = builder.snapshot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gunzip\n",
    "It's possible that one first has to unzip the dataset outside of any python code, to make it useable by e.g. awkward1 (hopefully).\n",
    "\n",
    "<a href=\"https://www.baeldung.com/linux/gzip-and-gunzip\" target=\"_blank\">https://www.baeldung.com/linux/gzip-and-gunzip</a>  \n",
    "<a href=\"https://unix.stackexchange.com/questions/156261/unzipping-a-gz-file-without-removing-the-gzipped-file/156324\" target=\"_blank\">https://unix.stackexchange.com/questions/156261/unzipping-a-gz-file-without-removing-the-gzipped-file/156324</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gunzip < /hpcwork/um106329/jet_flavor_MLPhysics/dataset/dataset.json.gz > /hpcwork/um106329/jet_flavor_MLPhysics/dataset/dataset.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it should be possible to try the previous methods again, but with decompressed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to awkward-arrays\n",
    "J. Pivarski's <a href=\"https://github.com/scikit-hep/awkward-1.0/issues/437#issuecomment-688389890\" target=\"_blank\">code</a>\n",
    "\n",
    "He got the number of lines via\n",
    "```\n",
    "wc -l dataset.json\n",
    "```\n",
    "and divided by 100 to be able to produce the printout of the progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11491971 /hpcwork/um106329/jet_flavor_MLPhysics/dataset/dataset.json\n"
     ]
    }
   ],
   "source": [
    "# just for info, it looks like that for me:\n",
    "!wc -l /hpcwork/um106329/jet_flavor_MLPhysics/dataset/dataset.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
      "Wall time: 11.4 µs\n",
      "23:27:58 : 0.0 percent complete\n",
      "23:28:08 : 1.0 percent complete\n",
      "23:28:17 : 2.0 percent complete\n",
      "23:28:25 : 3.0 percent complete\n",
      "23:28:33 : 4.0 percent complete\n",
      "23:28:40 : 5.0 percent complete\n",
      "23:28:49 : 6.0 percent complete\n",
      "23:28:57 : 7.0 percent complete\n",
      "23:29:05 : 8.0 percent complete\n",
      "23:29:14 : 9.0 percent complete\n",
      "23:29:22 : 10.0 percent complete\n",
      "23:29:30 : 11.0 percent complete\n",
      "23:29:37 : 12.0 percent complete\n",
      "23:29:44 : 13.0 percent complete\n",
      "23:29:53 : 14.0 percent complete\n",
      "23:30:03 : 15.0 percent complete\n",
      "23:30:10 : 16.0 percent complete\n",
      "23:30:18 : 17.0 percent complete\n",
      "23:30:25 : 18.0 percent complete\n",
      "23:30:33 : 19.0 percent complete\n",
      "23:30:43 : 20.0 percent complete\n",
      "23:30:50 : 21.0 percent complete\n",
      "23:31:00 : 22.0 percent complete\n",
      "23:31:08 : 23.0 percent complete\n",
      "23:31:15 : 24.0 percent complete\n",
      "23:31:23 : 25.0 percent complete\n",
      "23:31:31 : 26.0 percent complete\n",
      "23:31:38 : 27.0 percent complete\n",
      "23:31:46 : 28.0 percent complete\n",
      "23:31:54 : 29.0 percent complete\n",
      "23:32:05 : 30.0 percent complete\n",
      "23:32:12 : 31.0 percent complete\n",
      "23:32:20 : 32.0 percent complete\n",
      "23:32:31 : 33.0 percent complete\n",
      "23:32:39 : 34.0 percent complete\n",
      "23:32:46 : 35.0 percent complete\n",
      "23:32:53 : 36.0 percent complete\n",
      "23:33:01 : 37.0 percent complete\n",
      "23:33:08 : 38.0 percent complete\n",
      "23:33:16 : 39.0 percent complete\n",
      "23:33:23 : 40.0 percent complete\n",
      "23:33:32 : 41.0 percent complete\n",
      "23:33:39 : 42.0 percent complete\n",
      "23:33:46 : 43.0 percent complete\n",
      "23:33:52 : 44.0 percent complete\n",
      "23:34:05 : 45.0 percent complete\n",
      "23:34:10 : 46.0 percent complete\n",
      "23:34:16 : 47.0 percent complete\n",
      "23:34:22 : 48.0 percent complete\n",
      "23:34:28 : 49.0 percent complete\n",
      "23:34:34 : 50.0 percent complete\n",
      "23:34:40 : 51.0 percent complete\n",
      "23:34:45 : 52.0 percent complete\n",
      "23:34:58 : 53.0 percent complete\n",
      "23:35:04 : 54.0 percent complete\n",
      "23:35:10 : 55.0 percent complete\n",
      "23:35:16 : 56.0 percent complete\n",
      "23:35:22 : 57.0 percent complete\n",
      "23:35:28 : 58.0 percent complete\n",
      "23:35:35 : 59.0 percent complete\n",
      "23:35:41 : 60.0 percent complete\n",
      "23:35:47 : 61.0 percent complete\n",
      "23:35:53 : 62.0 percent complete\n",
      "23:36:01 : 63.0 percent complete\n",
      "23:36:07 : 64.0 percent complete\n",
      "23:36:13 : 65.0 percent complete\n",
      "23:36:20 : 66.0 percent complete\n",
      "23:36:26 : 67.0 percent complete\n",
      "23:36:33 : 68.0 percent complete\n",
      "23:36:38 : 69.0 percent complete\n",
      "23:36:44 : 70.0 percent complete\n",
      "23:36:50 : 71.0 percent complete\n",
      "23:36:56 : 72.0 percent complete\n",
      "23:37:02 : 73.0 percent complete\n",
      "23:37:07 : 74.0 percent complete\n",
      "23:37:25 : 75.0 percent complete\n",
      "23:37:32 : 76.0 percent complete\n",
      "23:37:37 : 77.0 percent complete\n",
      "23:37:43 : 78.0 percent complete\n",
      "23:37:49 : 79.0 percent complete\n",
      "23:37:54 : 80.0 percent complete\n",
      "23:38:00 : 81.0 percent complete\n",
      "23:38:06 : 82.0 percent complete\n",
      "23:38:13 : 83.0 percent complete\n",
      "23:38:18 : 84.0 percent complete\n",
      "23:38:25 : 85.0 percent complete\n",
      "23:38:31 : 86.0 percent complete\n",
      "23:38:37 : 87.0 percent complete\n",
      "23:38:42 : 88.0 percent complete\n",
      "23:38:59 : 89.0 percent complete\n",
      "23:39:05 : 90.0 percent complete\n",
      "23:39:11 : 91.0 percent complete\n",
      "23:39:18 : 92.0 percent complete\n",
      "23:39:23 : 93.0 percent complete\n",
      "23:39:30 : 94.0 percent complete\n",
      "23:39:37 : 95.0 percent complete\n",
      "23:39:43 : 96.0 percent complete\n",
      "23:39:50 : 97.0 percent complete\n",
      "23:39:56 : 98.0 percent complete\n",
      "23:40:01 : 99.0 percent complete\n",
      "23:40:07 : 100.0 percent complete\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "builder = ak.ArrayBuilder()\n",
    "for lineno, line in enumerate(open(dataset_path+\"dataset.json\")):\n",
    "    if lineno % 114919 == 0:\n",
    "        print(time.strftime(\"%H:%M:%S\"), \":\", lineno/114919, \"percent complete\")\n",
    "    builder.append(json.loads(line))\n",
    "array = builder.snapshot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Array [[47.9, 1.89, 5, [21.2, ... 6, 1]]]]] type='11491971 * var * union[float6...'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11491971"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_array = len(array)\n",
    "length_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's the correct number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An attempt to save the file in a better way, and split up\n",
    "Handle the file saving via parquet (pyarrow) from now on (said to be faster than parsing a \"jagged JSON\").\n",
    "\n",
    "<a href=\"https://stackoverflow.com/questions/66851761/best-way-to-save-a-dict-of-awkward1-arrays\" target=\"_blank\">https://stackoverflow.com/questions/66851761/best-way-to-save-a-dict-of-awkward1-arrays</a>\n",
    "\n",
    "Had to do `conda install -c conda-forge pyarrow` first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowNotImplementedError",
     "evalue": "Unhandled type for Arrow to Parquet schema conversion: dense_union<0: double=0, 1: list<item: dense_union<0: double=0, 1: list<item: list<item: dense_union<0: double=0, 1: string=1>>>=1, 2: string=2>>=1>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowNotImplementedError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-421dd111ffe3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mak\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'akArray_dataset.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/my-env/lib/python3.8/site-packages/awkward1/operations/convert.py\u001b[0m in \u001b[0;36mto_parquet\u001b[0;34m(array, where, explode_records, **options)\u001b[0m\n\u001b[1;32m   2496\u001b[0m         \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"schema\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2498\u001b[0;31m     \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyarrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParquetWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2499\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyarrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/my-env/lib/python3.8/site-packages/pyarrow/parquet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, where, schema, filesystem, flavor, version, use_dictionary, compression, write_statistics, use_deprecated_int96_timestamps, compression_level, use_byte_stream_split, writer_engine_version, data_page_version, **options)\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata_collector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'metadata_collector'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0mengine_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'V2'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         self.writer = _parquet.ParquetWriter(\n\u001b[0m\u001b[1;32m    555\u001b[0m             \u001b[0msink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/my-env/lib/python3.8/site-packages/pyarrow/_parquet.pyx\u001b[0m in \u001b[0;36mpyarrow._parquet.ParquetWriter.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/my-env/lib/python3.8/site-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowNotImplementedError\u001b[0m: Unhandled type for Arrow to Parquet schema conversion: dense_union<0: double=0, 1: list<item: dense_union<0: double=0, 1: list<item: list<item: dense_union<0: double=0, 1: string=1>>>=1, 2: string=2>>=1>"
     ]
    }
   ],
   "source": [
    "ak.to_parquet(array, dataset_path+'akArray_dataset.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some strings as placeholders for non-existing values, see also  \n",
    "<a href=\"https://github.com/scikit-hep/awkward-1.0/pull/568\" target=\"_blank\">https://github.com/scikit-hep/awkward-1.0/pull/568</a>  \n",
    "(redirected from <a href=\"https://github.com/scikit-hep/awkward-1.0/issues/437\" target=\"_blank\">https://github.com/scikit-hep/awkward-1.0/issues/437</a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix(x):\n",
    "    if isinstance(x, list):\n",
    "        return [fix(y) for y in x]\n",
    "    elif x == \"NaN\" or x == \"-NaN\":\n",
    "        return np.nan\n",
    "    elif x == \"inf\":\n",
    "        return np.inf\n",
    "    elif x == \"-inf\":\n",
    "        return -np.inf\n",
    "    elif isinstance(x, str):\n",
    "        raise Exception(\"unhandled string: \" + repr(x))\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = ak.ArrayBuilder()\n",
    "b2 = ak.ArrayBuilder()\n",
    "b3 = ak.ArrayBuilder()\n",
    "b4 = ak.ArrayBuilder()\n",
    "b5 = ak.ArrayBuilder()\n",
    "b6 = ak.ArrayBuilder()\n",
    "for lineno, line in enumerate(open(dataset_path+\"dataset.json\")):\n",
    "    if lineno % 114919 == 0:\n",
    "        print(time.strftime(\"%H:%M:%S\"), \":\", lineno/114919, \"percent complete\")\n",
    "    if lineno == 100000:\n",
    "        break\n",
    "    l1, l2, l3, l4, l5, l6 = fix(json.loads(line))\n",
    "    b1.append(l1)\n",
    "    b2.append(l2)\n",
    "    b3.append(l3)\n",
    "    b4.append(l4)\n",
    "    b5.append(l5)\n",
    "    b6.append(l6)\n",
    "    \n",
    "a1 = b1.snapshot()\n",
    "a2 = b2.snapshot()\n",
    "a3 = b3.snapshot()\n",
    "a4 = b4.snapshot()\n",
    "a5 = b5.snapshot()\n",
    "a6 = b6.snapshot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = ak.Array({\"a1\": a1, \"a2\": a2, \"a3\": a3, \"a4\": a4, \"a5\": a5, \"a6\": a6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.type(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Array [47.9, 35, 26.6, ... 25.1, 26.5, 27.8] type='100000 * float64'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Array [1.89, 0.61, -0.53, ... 2.28, -0.0922] type='100000 * float64'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Array [5, 5, 5, 5, 5, 5, ... 5, 5, 5, 0, 5, 5] type='100000 * int64'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Array [[21.2, 8.37, 29, ... 0.184, 0.144]] type='100000 * var * float64'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.a4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Array [[32.9, 3, 7, ... 0.264, 0.846, 0.489]] type='100000 * var * float64'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.a5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Array [[[[0.0312, 0.082, ... 2, 0.489]]]] type='100000 * var * var * var * float64'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.a6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.to_parquet(array, dataset_path+'akArray_0_99999'+'.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_array = ak.from_parquet(dataset_path+'akArray_0_99999'+'.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "akArray_0_99999.parquet  akArray_dataset.parquet  dataset.json\n",
      "akArray_0.parquet\t akArrays\t\t  dataset.json.gz\n"
     ]
    }
   ],
   "source": [
    "!ls /hpcwork/um106329/jet_flavor_MLPhysics/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir /hpcwork/um106329/jet_flavor_MLPhysics/dataset/akArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_arrays(a,b):\n",
    "    b1 = ak.ArrayBuilder()\n",
    "    b2 = ak.ArrayBuilder()\n",
    "    b3 = ak.ArrayBuilder()\n",
    "    b4 = ak.ArrayBuilder()\n",
    "    b5 = ak.ArrayBuilder()\n",
    "    b6 = ak.ArrayBuilder()\n",
    "    for lineno, line in enumerate(open(dataset_path+\"dataset.json\")):\n",
    "        if lineno < a:\n",
    "            continue\n",
    "        if lineno > (b-1):\n",
    "            break\n",
    "        l1, l2, l3, l4, l5, l6 = fix(json.loads(line))\n",
    "        b1.append(l1)\n",
    "        b2.append(l2)\n",
    "        b3.append(l3)\n",
    "        b4.append(l4)\n",
    "        b5.append(l5)\n",
    "        b6.append(l6)\n",
    "    \n",
    "    a1 = b1.snapshot()\n",
    "    a2 = b2.snapshot()\n",
    "    a3 = b3.snapshot()\n",
    "    a4 = b4.snapshot()\n",
    "    a5 = b5.snapshot()\n",
    "    a6 = b6.snapshot()\n",
    "    \n",
    "    array = ak.Array({\"a1\": a1, \"a2\": a2, \"a3\": a3, \"a4\": a4, \"a5\": a5, \"a6\": a6})\n",
    "    ak.to_parquet(array, dataset_path+'akArrays/split_{0}_{1}.parquet'.format(a,b-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = []\n",
    "total = 11491971\n",
    "for k in range(0,total,50000):\n",
    "    splits.append(k)\n",
    "splits.append(total)\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_arrays(0,100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm /hpcwork/um106329/jet_flavor_MLPhysics/dataset/akArrays/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /hpcwork/um106329/jet_flavor_MLPhysics/dataset/akArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 50000\n",
      "50000 100000\n",
      "100000 150000\n",
      "150000 200000\n",
      "200000 250000\n",
      "250000 300000\n",
      "300000 350000\n",
      "350000 400000\n",
      "400000 450000\n",
      "450000 500000\n",
      "500000 550000\n",
      "550000 600000\n",
      "600000 650000\n",
      "650000 700000\n",
      "700000 750000\n",
      "750000 800000\n",
      "800000 850000\n",
      "850000 900000\n",
      "900000 950000\n",
      "950000 1000000\n",
      "1000000 1050000\n",
      "1050000 1100000\n",
      "1100000 1150000\n",
      "1150000 1200000\n",
      "1200000 1250000\n",
      "1250000 1300000\n",
      "1300000 1350000\n",
      "1350000 1400000\n",
      "1400000 1450000\n",
      "1450000 1500000\n",
      "1500000 1550000\n",
      "1550000 1600000\n",
      "1600000 1650000\n",
      "1650000 1700000\n",
      "1700000 1750000\n",
      "1750000 1800000\n",
      "1800000 1850000\n",
      "1850000 1900000\n",
      "1900000 1950000\n",
      "1950000 2000000\n",
      "2000000 2050000\n",
      "2050000 2100000\n",
      "2100000 2150000\n",
      "2150000 2200000\n",
      "2200000 2250000\n",
      "2250000 2300000\n",
      "2300000 2350000\n",
      "2350000 2400000\n",
      "2400000 2450000\n",
      "2450000 2500000\n",
      "2500000 2550000\n",
      "2550000 2600000\n",
      "2600000 2650000\n",
      "2650000 2700000\n",
      "2700000 2750000\n",
      "2750000 2800000\n",
      "2800000 2850000\n",
      "2850000 2900000\n",
      "2900000 2950000\n",
      "2950000 3000000\n",
      "3000000 3050000\n",
      "3050000 3100000\n",
      "3100000 3150000\n",
      "3150000 3200000\n",
      "3200000 3250000\n",
      "3250000 3300000\n",
      "3300000 3350000\n",
      "3350000 3400000\n",
      "3400000 3450000\n",
      "3450000 3500000\n",
      "3500000 3550000\n",
      "3550000 3600000\n",
      "3600000 3650000\n",
      "3650000 3700000\n",
      "3700000 3750000\n",
      "3750000 3800000\n",
      "3800000 3850000\n",
      "3850000 3900000\n",
      "3900000 3950000\n",
      "3950000 4000000\n",
      "4000000 4050000\n",
      "4050000 4100000\n",
      "4100000 4150000\n",
      "4150000 4200000\n",
      "4200000 4250000\n",
      "4250000 4300000\n",
      "4300000 4350000\n",
      "4350000 4400000\n",
      "4400000 4450000\n",
      "4450000 4500000\n",
      "4500000 4550000\n",
      "4550000 4600000\n",
      "4600000 4650000\n",
      "4650000 4700000\n",
      "4700000 4750000\n",
      "4750000 4800000\n",
      "4800000 4850000\n",
      "4850000 4900000\n",
      "4900000 4950000\n",
      "4950000 5000000\n",
      "5000000 5050000\n",
      "5050000 5100000\n",
      "5100000 5150000\n",
      "5150000 5200000\n",
      "5200000 5250000\n",
      "5250000 5300000\n",
      "5300000 5350000\n",
      "5350000 5400000\n",
      "5400000 5450000\n",
      "5450000 5500000\n",
      "5500000 5550000\n",
      "5550000 5600000\n",
      "5600000 5650000\n",
      "5650000 5700000\n",
      "5700000 5750000\n",
      "5750000 5800000\n",
      "5800000 5850000\n",
      "5850000 5900000\n",
      "5900000 5950000\n",
      "5950000 6000000\n",
      "6000000 6050000\n",
      "6050000 6100000\n",
      "6100000 6150000\n",
      "6150000 6200000\n",
      "6200000 6250000\n",
      "6250000 6300000\n",
      "6300000 6350000\n",
      "6350000 6400000\n",
      "6400000 6450000\n",
      "6450000 6500000\n",
      "6500000 6550000\n",
      "6550000 6600000\n",
      "6600000 6650000\n",
      "6650000 6700000\n",
      "6700000 6750000\n",
      "6750000 6800000\n",
      "6800000 6850000\n",
      "6850000 6900000\n",
      "6900000 6950000\n",
      "6950000 7000000\n",
      "7000000 7050000\n",
      "7050000 7100000\n",
      "7100000 7150000\n",
      "7150000 7200000\n",
      "7200000 7250000\n",
      "7250000 7300000\n",
      "7300000 7350000\n",
      "7350000 7400000\n",
      "7400000 7450000\n",
      "7450000 7500000\n",
      "7500000 7550000\n",
      "7550000 7600000\n",
      "7600000 7650000\n",
      "7650000 7700000\n",
      "7700000 7750000\n",
      "7750000 7800000\n",
      "7800000 7850000\n",
      "7850000 7900000\n",
      "7900000 7950000\n",
      "7950000 8000000\n",
      "8000000 8050000\n",
      "8050000 8100000\n",
      "8100000 8150000\n",
      "8150000 8200000\n",
      "8200000 8250000\n",
      "8250000 8300000\n",
      "8300000 8350000\n",
      "8350000 8400000\n",
      "8400000 8450000\n",
      "8450000 8500000\n",
      "8500000 8550000\n",
      "8550000 8600000\n",
      "8600000 8650000\n",
      "8650000 8700000\n",
      "8700000 8750000\n",
      "8750000 8800000\n",
      "8800000 8850000\n",
      "8850000 8900000\n",
      "8900000 8950000\n",
      "8950000 9000000\n",
      "9000000 9050000\n",
      "9050000 9100000\n",
      "9100000 9150000\n",
      "9150000 9200000\n",
      "9200000 9250000\n",
      "9250000 9300000\n",
      "9300000 9350000\n",
      "9350000 9400000\n",
      "9400000 9450000\n",
      "9450000 9500000\n",
      "9500000 9550000\n",
      "9550000 9600000\n",
      "9600000 9650000\n",
      "9650000 9700000\n",
      "9700000 9750000\n",
      "9750000 9800000\n",
      "9800000 9850000\n",
      "9850000 9900000\n",
      "9900000 9950000\n",
      "9950000 10000000\n",
      "10000000 10050000\n",
      "10050000 10100000\n",
      "10100000 10150000\n",
      "10150000 10200000\n",
      "10200000 10250000\n",
      "10250000 10300000\n",
      "10300000 10350000\n",
      "10350000 10400000\n",
      "10400000 10450000\n",
      "10450000 10500000\n",
      "10500000 10550000\n",
      "10550000 10600000\n",
      "10600000 10650000\n",
      "10650000 10700000\n",
      "10700000 10750000\n",
      "10750000 10800000\n",
      "10800000 10850000\n",
      "10850000 10900000\n",
      "10900000 10950000\n",
      "10950000 11000000\n",
      "11000000 11050000\n",
      "11050000 11100000\n",
      "11100000 11150000\n",
      "11150000 11200000\n",
      "11200000 11250000\n",
      "11250000 11300000\n",
      "11300000 11350000\n",
      "11350000 11400000\n",
      "11400000 11450000\n",
      "11450000 11491971\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(splits)-1):\n",
    "    print(splits[i], splits[i+1])\n",
    "    fill_arrays(splits[i], splits[i+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fyi, this took ~1 hour on login18-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_0_49999.parquet\t\t split_4800000_4849999.parquet\n",
      "split_10000000_10049999.parquet  split_4850000_4899999.parquet\n",
      "split_1000000_1049999.parquet\t split_4900000_4949999.parquet\n",
      "split_100000_149999.parquet\t split_4950000_4999999.parquet\n",
      "split_10050000_10099999.parquet  split_5000000_5049999.parquet\n",
      "split_10100000_10149999.parquet  split_500000_549999.parquet\n",
      "split_10150000_10199999.parquet  split_50000_99999.parquet\n",
      "split_10200000_10249999.parquet  split_5050000_5099999.parquet\n",
      "split_10250000_10299999.parquet  split_5100000_5149999.parquet\n",
      "split_10300000_10349999.parquet  split_5150000_5199999.parquet\n",
      "split_10350000_10399999.parquet  split_5200000_5249999.parquet\n",
      "split_10400000_10449999.parquet  split_5250000_5299999.parquet\n",
      "split_10450000_10499999.parquet  split_5300000_5349999.parquet\n",
      "split_10500000_10549999.parquet  split_5350000_5399999.parquet\n",
      "split_1050000_1099999.parquet\t split_5400000_5449999.parquet\n",
      "split_10550000_10599999.parquet  split_5450000_5499999.parquet\n",
      "split_10600000_10649999.parquet  split_5500000_5549999.parquet\n",
      "split_10650000_10699999.parquet  split_550000_599999.parquet\n",
      "split_10700000_10749999.parquet  split_5550000_5599999.parquet\n",
      "split_10750000_10799999.parquet  split_5600000_5649999.parquet\n",
      "split_10800000_10849999.parquet  split_5650000_5699999.parquet\n",
      "split_10850000_10899999.parquet  split_5700000_5749999.parquet\n",
      "split_10900000_10949999.parquet  split_5750000_5799999.parquet\n",
      "split_10950000_10999999.parquet  split_5800000_5849999.parquet\n",
      "split_11000000_11049999.parquet  split_5850000_5899999.parquet\n",
      "split_1100000_1149999.parquet\t split_5900000_5949999.parquet\n",
      "split_11050000_11099999.parquet  split_5950000_5999999.parquet\n",
      "split_11100000_11149999.parquet  split_6000000_6049999.parquet\n",
      "split_11150000_11199999.parquet  split_600000_649999.parquet\n",
      "split_11200000_11249999.parquet  split_6050000_6099999.parquet\n",
      "split_11250000_11299999.parquet  split_6100000_6149999.parquet\n",
      "split_11300000_11349999.parquet  split_6150000_6199999.parquet\n",
      "split_11350000_11399999.parquet  split_6200000_6249999.parquet\n",
      "split_11400000_11449999.parquet  split_6250000_6299999.parquet\n",
      "split_11450000_11491970.parquet  split_6300000_6349999.parquet\n",
      "split_1150000_1199999.parquet\t split_6350000_6399999.parquet\n",
      "split_1200000_1249999.parquet\t split_6400000_6449999.parquet\n",
      "split_1250000_1299999.parquet\t split_6450000_6499999.parquet\n",
      "split_1300000_1349999.parquet\t split_6500000_6549999.parquet\n",
      "split_1350000_1399999.parquet\t split_650000_699999.parquet\n",
      "split_1400000_1449999.parquet\t split_6550000_6599999.parquet\n",
      "split_1450000_1499999.parquet\t split_6600000_6649999.parquet\n",
      "split_1500000_1549999.parquet\t split_6650000_6699999.parquet\n",
      "split_150000_199999.parquet\t split_6700000_6749999.parquet\n",
      "split_1550000_1599999.parquet\t split_6750000_6799999.parquet\n",
      "split_1600000_1649999.parquet\t split_6800000_6849999.parquet\n",
      "split_1650000_1699999.parquet\t split_6850000_6899999.parquet\n",
      "split_1700000_1749999.parquet\t split_6900000_6949999.parquet\n",
      "split_1750000_1799999.parquet\t split_6950000_6999999.parquet\n",
      "split_1800000_1849999.parquet\t split_7000000_7049999.parquet\n",
      "split_1850000_1899999.parquet\t split_700000_749999.parquet\n",
      "split_1900000_1949999.parquet\t split_7050000_7099999.parquet\n",
      "split_1950000_1999999.parquet\t split_7100000_7149999.parquet\n",
      "split_2000000_2049999.parquet\t split_7150000_7199999.parquet\n",
      "split_200000_249999.parquet\t split_7200000_7249999.parquet\n",
      "split_2050000_2099999.parquet\t split_7250000_7299999.parquet\n",
      "split_2100000_2149999.parquet\t split_7300000_7349999.parquet\n",
      "split_2150000_2199999.parquet\t split_7350000_7399999.parquet\n",
      "split_2200000_2249999.parquet\t split_7400000_7449999.parquet\n",
      "split_2250000_2299999.parquet\t split_7450000_7499999.parquet\n",
      "split_2300000_2349999.parquet\t split_7500000_7549999.parquet\n",
      "split_2350000_2399999.parquet\t split_750000_799999.parquet\n",
      "split_2400000_2449999.parquet\t split_7550000_7599999.parquet\n",
      "split_2450000_2499999.parquet\t split_7600000_7649999.parquet\n",
      "split_2500000_2549999.parquet\t split_7650000_7699999.parquet\n",
      "split_250000_299999.parquet\t split_7700000_7749999.parquet\n",
      "split_2550000_2599999.parquet\t split_7750000_7799999.parquet\n",
      "split_2600000_2649999.parquet\t split_7800000_7849999.parquet\n",
      "split_2650000_2699999.parquet\t split_7850000_7899999.parquet\n",
      "split_2700000_2749999.parquet\t split_7900000_7949999.parquet\n",
      "split_2750000_2799999.parquet\t split_7950000_7999999.parquet\n",
      "split_2800000_2849999.parquet\t split_8000000_8049999.parquet\n",
      "split_2850000_2899999.parquet\t split_800000_849999.parquet\n",
      "split_2900000_2949999.parquet\t split_8050000_8099999.parquet\n",
      "split_2950000_2999999.parquet\t split_8100000_8149999.parquet\n",
      "split_3000000_3049999.parquet\t split_8150000_8199999.parquet\n",
      "split_300000_349999.parquet\t split_8200000_8249999.parquet\n",
      "split_3050000_3099999.parquet\t split_8250000_8299999.parquet\n",
      "split_3100000_3149999.parquet\t split_8300000_8349999.parquet\n",
      "split_3150000_3199999.parquet\t split_8350000_8399999.parquet\n",
      "split_3200000_3249999.parquet\t split_8400000_8449999.parquet\n",
      "split_3250000_3299999.parquet\t split_8450000_8499999.parquet\n",
      "split_3300000_3349999.parquet\t split_8500000_8549999.parquet\n",
      "split_3350000_3399999.parquet\t split_850000_899999.parquet\n",
      "split_3400000_3449999.parquet\t split_8550000_8599999.parquet\n",
      "split_3450000_3499999.parquet\t split_8600000_8649999.parquet\n",
      "split_3500000_3549999.parquet\t split_8650000_8699999.parquet\n",
      "split_350000_399999.parquet\t split_8700000_8749999.parquet\n",
      "split_3550000_3599999.parquet\t split_8750000_8799999.parquet\n",
      "split_3600000_3649999.parquet\t split_8800000_8849999.parquet\n",
      "split_3650000_3699999.parquet\t split_8850000_8899999.parquet\n",
      "split_3700000_3749999.parquet\t split_8900000_8949999.parquet\n",
      "split_3750000_3799999.parquet\t split_8950000_8999999.parquet\n",
      "split_3800000_3849999.parquet\t split_9000000_9049999.parquet\n",
      "split_3850000_3899999.parquet\t split_900000_949999.parquet\n",
      "split_3900000_3949999.parquet\t split_9050000_9099999.parquet\n",
      "split_3950000_3999999.parquet\t split_9100000_9149999.parquet\n",
      "split_4000000_4049999.parquet\t split_9150000_9199999.parquet\n",
      "split_400000_449999.parquet\t split_9200000_9249999.parquet\n",
      "split_4050000_4099999.parquet\t split_9250000_9299999.parquet\n",
      "split_4100000_4149999.parquet\t split_9300000_9349999.parquet\n",
      "split_4150000_4199999.parquet\t split_9350000_9399999.parquet\n",
      "split_4200000_4249999.parquet\t split_9400000_9449999.parquet\n",
      "split_4250000_4299999.parquet\t split_9450000_9499999.parquet\n",
      "split_4300000_4349999.parquet\t split_9500000_9549999.parquet\n",
      "split_4350000_4399999.parquet\t split_950000_999999.parquet\n",
      "split_4400000_4449999.parquet\t split_9550000_9599999.parquet\n",
      "split_4450000_4499999.parquet\t split_9600000_9649999.parquet\n",
      "split_4500000_4549999.parquet\t split_9650000_9699999.parquet\n",
      "split_450000_499999.parquet\t split_9700000_9749999.parquet\n",
      "split_4550000_4599999.parquet\t split_9750000_9799999.parquet\n",
      "split_4600000_4649999.parquet\t split_9800000_9849999.parquet\n",
      "split_4650000_4699999.parquet\t split_9850000_9899999.parquet\n",
      "split_4700000_4749999.parquet\t split_9900000_9949999.parquet\n",
      "split_4750000_4799999.parquet\t split_9950000_9999999.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls /hpcwork/um106329/jet_flavor_MLPhysics/dataset/akArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2G\t/hpcwork/um106329/jet_flavor_MLPhysics/dataset/akArrays\n"
     ]
    }
   ],
   "source": [
    "!du -sh /hpcwork/um106329/jet_flavor_MLPhysics/dataset/akArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16G\t/hpcwork/um106329/jet_flavor_MLPhysics/dataset/dataset.json\n"
     ]
    }
   ],
   "source": [
    "!du -sh /hpcwork/um106329/jet_flavor_MLPhysics/dataset/dataset.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3G\t/hpcwork/um106329/jet_flavor_MLPhysics/dataset/dataset.json.gz\n"
     ]
    }
   ],
   "source": [
    "!du -sh /hpcwork/um106329/jet_flavor_MLPhysics/dataset/dataset.json.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which means: the least amount of space is used by the zipped file. After decompressing, it gets very large, and takes a long time to read = bad. Now, the arrays saved by awkward1 take only twice as much space as the original, zipped file, but the reading is much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.7 s, sys: 14.3 s, total: 41 s\n",
      "Wall time: 49.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(len(splits)-1):\n",
    "    array = ak.from_parquet(dataset_path+'akArrays/split_{0}_{1}.parquet'.format(splits[i],splits[i+1]-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
